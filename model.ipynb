{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load CSV data into a pandas DataFrame\"\"\"\n",
    "    return pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Exploratory Data Analysis\n",
    "def perform_eda(df):\n",
    "    \"\"\"Perform basic exploratory data analysis\"\"\"\n",
    "    print(\"Data shape:\", df.shape)\n",
    "    print(\"\\nData info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nDescriptive statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Visualizations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Histogram for each numerical feature\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for i, col in enumerate(numerical_cols[:min(6, len(numerical_cols))]):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        sns.histplot(df[col], kde=True)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    corr_matrix = df.select_dtypes(include=['int64', 'float64']).corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Bar plots for categorical features\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in categorical_cols[:min(4, len(categorical_cols))]:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        df[col].value_counts().plot(kind='bar')\n",
    "        plt.title(f'Count of {col}')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Preprocessing\n",
    "def create_preprocessing_pipeline(numerical_features, categorical_features, ordinal_features=None, ordinal_categories=None):\n",
    "    \"\"\"\n",
    "    Create a column transformer for preprocessing different feature types\n",
    "    abc\n",
    "    Parameters:\n",
    "    -----------\n",
    "    numerical_features : list\n",
    "        List of numerical feature names\n",
    "    categorical_features : list\n",
    "        List of categorical feature names\n",
    "    ordinal_features : list, optional\n",
    "        List of ordinal feature names\n",
    "    ordinal_categories : list of lists, optional\n",
    "        List of category orders for each ordinal feature\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    ColumnTransformer\n",
    "        Preprocessor for the features\n",
    "    \"\"\"\n",
    "    transformers = []\n",
    "    \n",
    "    # Add numerical preprocessor\n",
    "    if numerical_features:\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        transformers.append(('num', numerical_transformer, numerical_features))\n",
    "    \n",
    "    # Add categorical preprocessor\n",
    "    if categorical_features:\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ])\n",
    "        transformers.append(('cat', categorical_transformer, categorical_features))\n",
    "    \n",
    "    # Add ordinal preprocessor\n",
    "    if ordinal_features and ordinal_categories:\n",
    "        ordinal_transformer = Pipeline(steps=[\n",
    "            ('ordinal', OrdinalEncoder(categories=ordinal_categories))\n",
    "        ])\n",
    "        transformers.append(('ord', ordinal_transformer, ordinal_features))\n",
    "    \n",
    "    # Create column transformer\n",
    "    preprocessor = ColumnTransformer(transformers=transformers)\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Building and Evaluation\n",
    "def build_and_evaluate_model(X_train, X_test, y_train, y_test, preprocessor, model_type='random_forest'):\n",
    "    \"\"\"\n",
    "    Build a model pipeline, fit it to the training data, and evaluate it\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, X_test : DataFrame\n",
    "        Training and test feature sets\n",
    "    y_train, y_test : Series\n",
    "        Training and test target values\n",
    "    preprocessor : ColumnTransformer\n",
    "        Feature preprocessor\n",
    "    model_type : str, optional\n",
    "        Type of model to use ('linear' or 'random_forest')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : Pipeline\n",
    "        Fitted model pipeline\n",
    "    \"\"\"\n",
    "    # Select model\n",
    "    if model_type == 'linear':\n",
    "        model = LinearRegression()\n",
    "    else:  # random_forest\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Fit model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluate model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    # Plot predicted vs actual\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Actual vs Predicted Values')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Hyperparameter Tuning\n",
    "def tune_hyperparameters(X_train, y_train, preprocessor, model_type='random_forest'):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning with GridSearchCV\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : DataFrame\n",
    "        Training features\n",
    "    y_train : Series\n",
    "        Training target values\n",
    "    preprocessor : ColumnTransformer\n",
    "        Feature preprocessor\n",
    "    model_type : str, optional\n",
    "        Type of model to use ('linear' or 'random_forest')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    best_model : GridSearchCV\n",
    "        Tuned model with best parameters\n",
    "    \"\"\"\n",
    "    # Create base pipeline\n",
    "    if model_type == 'linear':\n",
    "        model = LinearRegression()\n",
    "        param_grid = {\n",
    "            # Linear regression doesn't have many hyperparameters to tune\n",
    "            'model__fit_intercept': [True, False],\n",
    "            'model__positive': [True, False]\n",
    "        }\n",
    "    else:  # random_forest\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'model__n_estimators': [50, 100, 200],\n",
    "            'model__max_depth': [None, 10, 20, 30],\n",
    "            'model__min_samples_split': [2, 5, 10],\n",
    "            'model__min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Create grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nHyperparameter Tuning Results:\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best Score (Neg MSE): {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to tie everything together\n",
    "def main():\n",
    "    # Load data\n",
    "    filepath = \"your_data.csv\"  # REPLACE WITH YOUR CSV PATH\n",
    "    df = load_data(filepath)\n",
    "    \n",
    "    # Perform EDA\n",
    "    df = perform_eda(df)\n",
    "    \n",
    "    # Define features and target\n",
    "    target_column = \"target\"  # REPLACE WITH YOUR TARGET COLUMN\n",
    "    \n",
    "    # REPLACE THESE WITH YOUR ACTUAL COLUMN NAMES\n",
    "    numerical_features = [\"num_feature1\", \"num_feature2\", \"num_feature3\"]\n",
    "    categorical_features = [\"cat_feature1\", \"cat_feature2\"]\n",
    "    ordinal_features = [\"ord_feature1\"]\n",
    "    ordinal_categories = [[\"low\", \"medium\", \"high\"]]  # Categories in order\n",
    "    \n",
    "    # Split data\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Create preprocessor\n",
    "    preprocessor = create_preprocessing_pipeline(\n",
    "        numerical_features, \n",
    "        categorical_features, \n",
    "        ordinal_features, \n",
    "        ordinal_categories\n",
    "    )\n",
    "    \n",
    "    # Build and evaluate base model\n",
    "    model = build_and_evaluate_model(X_train, X_val, y_train, y_val, preprocessor, model_type='random_forest')\n",
    "    \n",
    "    # Tune hyperparameters\n",
    "    best_model = tune_hyperparameters(X_train, y_train, preprocessor, model_type='random_forest')\n",
    "    \n",
    "    # Evaluate best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nFinal Model Evaluation (Test Set):\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {np.sqrt(mse):.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
