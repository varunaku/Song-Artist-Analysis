{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: billboard.py in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (7.1.0)\n",
      "Requirement already satisfied: lyricsgenius in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (3.3.1)\n",
      "Requirement already satisfied: pandas in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from billboard.py) (4.13.3)\n",
      "Requirement already satisfied: requests>=2.2.1 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from billboard.py) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->billboard.py) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->billboard.py) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (2024.6.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (3.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install billboard.py lyricsgenius pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: billboard.py 7.1.0\n",
      "Uninstalling billboard.py-7.1.0:\n",
      "  Successfully uninstalled billboard.py-7.1.0\n",
      "Collecting billboard.py\n",
      "  Using cached billboard.py-7.1.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests>=2.2.1 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from billboard.py) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from billboard.py) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->billboard.py) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->billboard.py) (4.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (2024.6.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.2.1->billboard.py) (2.1.0)\n",
      "Installing collected packages: billboard.py\n",
      "Successfully installed billboard.py-7.1.0\n",
      "Name: billboard.py\n",
      "Version: 7.1.0\n",
      "Summary: Python API for downloading Billboard charts\n",
      "Home-page: https://github.com/guoguo12/billboard-charts\n",
      "Author: Allen Guo\n",
      "Author-email: guoguo12@gmail.com\n",
      "License: MIT License\n",
      "Location: /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages\n",
      "Requires: beautifulsoup4, requests\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip uninstall billboard.py -y\n",
    "!pip install billboard.py\n",
    "!pip show billboard.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spotipy in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (2.25.1)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests>=2.25.0 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from spotipy) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from spotipy) (2.1.0)\n",
      "Requirement already satisfied: redis>=3.5.3 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from spotipy) (5.2.1)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from redis>=3.5.3->spotipy) (5.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2024.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/varun/miniconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (3.6)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install spotipy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spotify API...\n",
      "FATAL ERROR: Could not initialize Spotify API: error: invalid_client, error_description: Invalid client secret\n",
      "Spotify data fetching will be disabled.\n",
      "\n",
      "--- Starting Data Collection for hot-100 ---\n",
      "Starting date generation from most recent Saturday: 2025-03-29\n",
      "Generated 1 chart dates, from 2025-03-29 back to 2025-03-29.\n",
      "\n",
      "Fetching Billboard chart 1/1 for date: 2025-03-29\n",
      "  Successfully fetched Billboard chart with 100 entries.\n",
      "  Processing Billboard Entry #1: 'Luther' by Kendrick Lamar & SZA\n",
      "  Processing Billboard Entry #2: 'Evil J0rdan' by Playboi Carti\n",
      "\n",
      "--- Data Collection Finished ---\n",
      "\n",
      "--- Processing Collected Data ---\n",
      "Created initial DataFrame with 2 rows and 28 columns.\n",
      "Cleaning data and converting types...\n",
      "Converting numeric columns: ['rank', 'peak_pos', 'last_pos', 'weeks_on_chart', 'popularity', 'duration_ms', 'album_total_tracks']\n",
      "\n",
      "Calculating Artist Success Score (based on Billboard data)...\n",
      "  Aggregating best performance for each unique song by artist (Billboard data)...\n",
      "  Aggregated performance for 2 unique artist-song combinations.\n",
      "  Summing song scores to get final artist scores...\n",
      "\n",
      "Calculated success scores for 2 artists (Billboard names).\n",
      "Top 10 Artists by Calculated Success Score:\n",
      "artist\n",
      "Kendrick Lamar & SZA    328.903718\n",
      "Playboi Carti           155.931472\n",
      "Name: total_song_score, dtype: float64\n",
      "\n",
      "Filtering for 'Bigger Artists' (Top 50% by score)...\n",
      "  Score threshold: 242.42\n",
      "  Identified 1 artists meeting the threshold.\n",
      "  DataFrame filtered to 1 rows for bigger artists.\n",
      "Adding Artist Success Score column to the DataFrame...\n",
      "\n",
      "Genre Filtering Section (Target Keyword: 'pop')\n",
      "  Genre filtering is currently disabled (PERFORM_GENRE_FILTER = False).\n",
      "\n",
      "--- Preparing Final Data and Saving ---\n",
      "Ensuring all final columns exist...\n",
      "\n",
      "Final processed dataset contains 1 rows and 29 columns.\n",
      "\n",
      "Successfully saved final filtered data to: hot-100_spotify_filtered_bigger_artists.csv\n",
      "\n",
      "--- Script Execution Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/vnb75kgd62vbpkcfcrpdr5v00000gn/T/ipykernel_97339/557072836.py:351: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_filtered['artist_success_score'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import billboard\n",
    "import spotipy \n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "spotify_CLIENT_ID = os.getenv(\"spotify_CLIENT_ID\")\n",
    "spotify_CLIENT_SECRET = (\"spotify_CLIENT_SECRET\")\n",
    "\n",
    "CHART_NAME = 'hot-100' \n",
    "OUTPUT_CSV_FILE = f'{CHART_NAME}_spotify_filtered_bigger_artists.csv' \n",
    "NUMBER_OF_WEEKS_TO_FETCH = 1\n",
    "MAX_SONGS_PER_CHART = 2\n",
    "FETCH_SPOTIFY_DATA = True \n",
    "\n",
    "BILLBOARD_DELAY = 2 \n",
    "SPOTIFY_DELAY = 0.5 \n",
    "\n",
    "ARTIST_SCORE_THRESHOLD_PERCENTILE = 0.5 # Keep top 50% artists by score\n",
    "W_PEAK = 1.0        # Importance of peak position\n",
    "W_LONGEVITY = 10.0  # Importance of longevity (log scaled)\n",
    "B_TOP10 = 50        # Bonus for Top 10\n",
    "B_NUM1 = 150        # Bonus for #1\n",
    "\n",
    "TARGET_GENRE_KEYWORD = 'pop' \n",
    "# Set to True to enable filtering based on Spotify's artist/album genres\n",
    "PERFORM_GENRE_FILTER = False # Keep False initially, enable after verifying genre data\n",
    "\n",
    "# --- Initialize Spotify API ---\n",
    "sp = None # Initialize sp to None\n",
    "if FETCH_SPOTIFY_DATA:\n",
    "    if spotify_CLIENT_ID == 'YOUR_SPOTIFY_CLIENT_ID' or spotify_CLIENT_SECRET == 'YOUR_SPOTIFY_CLIENT_SECRET':\n",
    "        raise ValueError(\"CRITICAL: Set your spotify_CLIENT_ID and spotify_CLIENT_SECRET.\")\n",
    "    try:\n",
    "        print(\"Initializing Spotify API...\")\n",
    "        client_credentials_manager = SpotifyClientCredentials(client_id=spotify_CLIENT_ID, client_secret=spotify_CLIENT_SECRET)\n",
    "        sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "        # Make a test call to ensure authentication works\n",
    "        sp.search(q='test', limit=1)\n",
    "        print(\"Spotify API initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL ERROR: Could not initialize Spotify API: {e}\")\n",
    "        print(\"Spotify data fetching will be disabled.\")\n",
    "        FETCH_SPOTIFY_DATA = False\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def get_chart_dates(num_weeks):\n",
    "    \"\"\"Generates a list of PAST Saturday dates in 'YYYY-MM-DD' format.\"\"\"\n",
    "    # (Code unchanged from previous correct version)\n",
    "    dates = []\n",
    "    today = datetime.date.today()\n",
    "    current_saturday = today - datetime.timedelta(days=(today.weekday() + 2) % 7)\n",
    "    print(f\"Starting date generation from most recent Saturday: {current_saturday}\")\n",
    "    for i in range(num_weeks):\n",
    "        chart_date_dt = current_saturday - datetime.timedelta(weeks=i)\n",
    "        chart_date_str = chart_date_dt.strftime('%Y-%m-%d')\n",
    "        dates.append(chart_date_str)\n",
    "    print(f\"Generated {len(dates)} chart dates, from {dates[0]} back to {dates[-1]}.\")\n",
    "    return dates\n",
    "\n",
    "def clean_search_query(text):\n",
    "    \"\"\"Removes common variations like 'feat.', 'Remix', etc., for better API matching.\"\"\"\n",
    "    # (Code unchanged from previous correct version)\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\sfeat\\.?\\s.*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\sx\\s.*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s&\\s.*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\swith\\s.*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\(.*Remix.*\\)', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\(.*Radio Edit.*\\)', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s*\\(.*\\)', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def parse_release_date(date_str, precision):\n",
    "    \"\"\"Parses Spotify release date based on precision.\"\"\"\n",
    "    try:\n",
    "        if precision == 'day':\n",
    "            return pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "        elif precision == 'month':\n",
    "            return pd.to_datetime(date_str + '-01', format='%Y-%m-%d') # Assume 1st of month\n",
    "        elif precision == 'year':\n",
    "            return pd.to_datetime(date_str + '-01-01', format='%Y-%d-%m') # Assume Jan 1st\n",
    "        else:\n",
    "            return pd.NaT # Not a Time for unknown precision\n",
    "    except ValueError:\n",
    "        return pd.NaT # Handle parsing errors\n",
    "\n",
    "def fetch_spotify_track_data(sp_client, artist_name, track_title):\n",
    "    \"\"\"Fetches metadata for a track from Spotify API.\"\"\"\n",
    "    if not FETCH_SPOTIFY_DATA or sp_client is None:\n",
    "        return None # Skip if disabled or client not initialized\n",
    "\n",
    "    # Clean inputs for better search\n",
    "    search_artist = clean_search_query(artist_name).split(',')[0].split('&')[0].strip() # Primary artist\n",
    "    search_track = clean_search_query(track_title)\n",
    "    query = f'artist:\"{search_artist}\" track:\"{search_track}\"' # Use quotes for more exact match\n",
    "\n",
    "    # print(f\"    Searching Spotify: {query}\") # Uncomment for debug logs\n",
    "    try:\n",
    "        results = sp_client.search(q=query, type='track', limit=1)\n",
    "        time.sleep(SPOTIFY_DELAY) # Pause after API call\n",
    "\n",
    "        if results and results['tracks']['items']:\n",
    "            track = results['tracks']['items'][0]\n",
    "            album = track['album'] # Album info associated with the track\n",
    "\n",
    "            # Basic track info\n",
    "            spotify_data = {\n",
    "                'spotify_id': track.get('id'),\n",
    "                'spotify_track_name': track.get('name'),\n",
    "                'spotify_primary_artist': track['artists'][0].get('name') if track.get('artists') else None,\n",
    "                'spotify_all_artists': ', '.join([a.get('name', '') for a in track.get('artists', [])]),\n",
    "                'spotify_track_url': track['external_urls'].get('spotify'),\n",
    "                'popularity': track.get('popularity'),\n",
    "                'duration_ms': track.get('duration_ms'),\n",
    "                'explicit': track.get('explicit'),\n",
    "\n",
    "                # Album info from the track object\n",
    "                'album_id': album.get('id'),\n",
    "                'album_name': album.get('name'),\n",
    "                'album_release_date': parse_release_date(album.get('release_date'), album.get('release_date_precision')),\n",
    "                'album_total_tracks': album.get('total_tracks'),\n",
    "                'album_url': album['external_urls'].get('spotify'),\n",
    "                'album_genres': ', '.join(album.get('genres', [])), # Genres often on album\n",
    "                'album_label': album.get('label'), # Sometimes label info is here\n",
    "\n",
    "                # Artist genres (often more reliable than album genres)\n",
    "                'artist_genres': None, # Placeholder, fetch below\n",
    "\n",
    "                # Placeholders for harder-to-get credits\n",
    "                'writers': None, # Often requires external linking or parsing copyrights\n",
    "                'producers': None, # Often requires external linking or parsing copyrights\n",
    "                'album_copyrights': None # Fetch below\n",
    "            }\n",
    "\n",
    "            # --- Fetch Additional Details (Optional, adds API calls) ---\n",
    "            # Get Artist Genres (more reliable source)\n",
    "            if track.get('artists'):\n",
    "                try:\n",
    "                    artist_id = track['artists'][0].get('id')\n",
    "                    if artist_id:\n",
    "                        artist_details = sp_client.artist(artist_id)\n",
    "                        time.sleep(SPOTIFY_DELAY)\n",
    "                        spotify_data['artist_genres'] = ', '.join(artist_details.get('genres', []))\n",
    "                except Exception as e_artist:\n",
    "                    print(f\"      WARN: Could not fetch artist details for {artist_id}: {e_artist}\")\n",
    "\n",
    "            # Get Album Copyrights (might contain writer/producer info textually)\n",
    "            if spotify_data['album_id']:\n",
    "                 try:\n",
    "                     album_details = sp_client.album(spotify_data['album_id'])\n",
    "                     time.sleep(SPOTIFY_DELAY)\n",
    "                     spotify_data['album_copyrights'] = ', '.join([c.get('text', '') for c in album_details.get('copyrights', [])])\n",
    "                 except Exception as e_album:\n",
    "                     print(f\"      WARN: Could not fetch album details for {spotify_data['album_id']}: {e_album}\")\n",
    "\n",
    "            # print(f\"    Found on Spotify: {spotify_data['spotify_track_name']} by {spotify_data['spotify_primary_artist']}\") # Uncomment for debug\n",
    "            return spotify_data\n",
    "        else:\n",
    "            # print(f\"    Not found on Spotify.\") # Uncomment for debug\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"    WARNING: Error fetching Spotify data for '{track_title}' by '{artist_name}': {e}\")\n",
    "        time.sleep(SPOTIFY_DELAY * 2) # Longer pause after error\n",
    "        return None\n",
    "\n",
    "# --- Main Data Collection ---\n",
    "print(f\"\\n--- Starting Data Collection for {CHART_NAME} ---\")\n",
    "all_chart_entries = []\n",
    "chart_dates = get_chart_dates(NUMBER_OF_WEEKS_TO_FETCH)\n",
    "\n",
    "# Loop through each calculated chart date\n",
    "for i, chart_date in enumerate(chart_dates):\n",
    "    print(f\"\\nFetching Billboard chart {i+1}/{len(chart_dates)} for date: {chart_date}\")\n",
    "    try:\n",
    "        # Fetch chart data for the specific date\n",
    "        chart = billboard.ChartData(CHART_NAME, date=chart_date) # Use billboard.Chart\n",
    "        print(f\"  Successfully fetched Billboard chart with {len(chart)} entries.\")\n",
    "        time.sleep(BILLBOARD_DELAY) # Pause between Billboard fetches\n",
    "\n",
    "        # Process each song entry on the chart for that week\n",
    "        for entry_rank, entry in enumerate(chart[:MAX_SONGS_PER_CHART]):\n",
    "            print(f\"  Processing Billboard Entry #{entry_rank+1}: '{entry.title}' by {entry.artist}\")\n",
    "            # Basic song data from Billboard\n",
    "            billboard_info = {\n",
    "                'chart_date': chart_date, # String 'YYYY-MM-DD'\n",
    "                'chart_name': CHART_NAME,\n",
    "                'rank': entry.rank,\n",
    "                'title': entry.title,\n",
    "                'artist': entry.artist, # Original artist string from Billboard\n",
    "                'peak_pos': entry.peakPos,\n",
    "                'last_pos': entry.lastPos,\n",
    "                'weeks_on_chart': entry.weeks,\n",
    "                'is_new': entry.isNew,\n",
    "            }\n",
    "\n",
    "            # Attempt to fetch complementary data from Spotify\n",
    "            spotify_data = fetch_spotify_track_data(sp, entry.artist, entry.title)\n",
    "\n",
    "            # Combine Billboard data with Spotify data (if found)\n",
    "            if spotify_data:\n",
    "                billboard_info.update(spotify_data)\n",
    "            else:\n",
    "                # Add placeholder keys if Spotify data wasn't found or fetch failed\n",
    "                spotify_placeholders = {\n",
    "                    'spotify_id': None, 'spotify_track_name': None, 'spotify_primary_artist': None,\n",
    "                    'spotify_all_artists': None, 'spotify_track_url': None, 'popularity': None,\n",
    "                    'duration_ms': None, 'explicit': None, 'album_id': None, 'album_name': None,\n",
    "                    'album_release_date': None, 'album_total_tracks': None, 'album_url': None,\n",
    "                    'album_genres': None, 'artist_genres': None, 'album_label': None, 'writers': None,\n",
    "                    'producers': None, 'album_copyrights': None\n",
    "                }\n",
    "                billboard_info.update(spotify_placeholders)\n",
    "\n",
    "            # Add the combined entry to our master list\n",
    "            all_chart_entries.append(billboard_info)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  WARNING: Could not fetch or process Billboard chart for {chart_date}. Error: {e}\")\n",
    "        print(f\"  Skipping this date.\")\n",
    "        time.sleep(BILLBOARD_DELAY * 2)\n",
    "        continue # Skip to the next date\n",
    "\n",
    "print(\"\\n--- Data Collection Finished ---\")\n",
    "\n",
    "# --- Data Processing and Feature Engineering ---\n",
    "\n",
    "if not all_chart_entries:\n",
    "    print(\"FATAL: No data was collected (likely due to chart fetching errors). Exiting.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\n--- Processing Collected Data ---\")\n",
    "df = pd.DataFrame(all_chart_entries)\n",
    "print(f\"Created initial DataFrame with {len(df)} rows and {len(df.columns)} columns.\")\n",
    "# print(\"Initial DataFrame columns:\", df.columns.tolist()) # Uncomment to debug columns\n",
    "\n",
    "# --- Basic Cleaning & Type Conversion ---\n",
    "print(\"Cleaning data and converting types...\")\n",
    "# Convert date columns (chart_date is string, album_release_date should be datetime)\n",
    "if 'chart_date' in df.columns:\n",
    "    df['chart_date'] = pd.to_datetime(df['chart_date'], errors='coerce')\n",
    "if 'album_release_date' in df.columns:\n",
    "    # Already parsed to datetime or NaT in fetch function\n",
    "    pass # df['album_release_date'] = pd.to_datetime(df['album_release_date'], errors='coerce')\n",
    "\n",
    "# Convert numerical columns\n",
    "numeric_cols = ['rank', 'peak_pos', 'last_pos', 'weeks_on_chart', 'popularity', 'duration_ms', 'album_total_tracks']\n",
    "print(\"Converting numeric columns:\", numeric_cols)\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        # Handle potential non-numeric placeholders before conversion\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        nan_count = df[col].isna().sum()\n",
    "        if nan_count > 0 and nan_count < len(df): # Don't warn if column is entirely NaN\n",
    "             print(f\"  INFO: Column '{col}' has {nan_count} NaN values after conversion.\")\n",
    "    else:\n",
    "        print(f\"  WARNING: Numeric column '{col}' not found. Adding as empty.\")\n",
    "        df[col] = np.nan\n",
    "\n",
    "# Convert boolean columns\n",
    "for col in ['is_new', 'explicit']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('boolean') # Use Pandas nullable boolean type\n",
    "    else:\n",
    "        print(f\"  WARNING: Boolean column '{col}' not found. Adding as False.\")\n",
    "        df[col] = False\n",
    "\n",
    "\n",
    "# --- Calculate Artist Success Score ---\n",
    "# Uses Billboard 'artist' string and chart data. Logic remains the same.\n",
    "print(\"\\nCalculating Artist Success Score (based on Billboard data)...\")\n",
    "# (Function definition calculate_artist_success unchanged from previous version)\n",
    "def calculate_artist_success(df_calc, w_peak, w_longevity, b_top10, b_num1):\n",
    "    required_cols = ['artist', 'title', 'peak_pos', 'weeks_on_chart']\n",
    "    if not all(col in df_calc.columns for col in required_cols):\n",
    "        print(\"  WARNING: Missing required columns for score calculation:\", [col for col in required_cols if col not in df_calc.columns])\n",
    "        return pd.Series(dtype=float)\n",
    "    print(\"  Aggregating best performance for each unique song by artist (Billboard data)...\")\n",
    "    df_calc_cleaned = df_calc.dropna(subset=required_cols)\n",
    "    if df_calc_cleaned.empty:\n",
    "        print(\"  WARNING: No valid data remaining after cleaning for score calculation.\")\n",
    "        return pd.Series(dtype=float)\n",
    "    try:\n",
    "        song_summary = df_calc_cleaned.groupby(['artist', 'title'], observed=True).agg(\n",
    "            song_peak_pos=('peak_pos', 'min'),\n",
    "            song_weeks_on_chart=('weeks_on_chart', 'max')\n",
    "        ).reset_index()\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR during groupby/aggregation for score calculation: {e}\")\n",
    "        return pd.Series(dtype=float)\n",
    "    print(f\"  Aggregated performance for {len(song_summary)} unique artist-song combinations.\")\n",
    "    song_summary['peak_score'] = w_peak * (101 - song_summary['song_peak_pos'])\n",
    "    song_summary['longevity_score'] = w_longevity * np.log1p(song_summary['song_weeks_on_chart'])\n",
    "    song_summary['top10_bonus'] = np.where(song_summary['song_peak_pos'] <= 10, b_top10, 0)\n",
    "    song_summary['num1_bonus'] = np.where(song_summary['song_peak_pos'] == 1, b_num1, 0)\n",
    "    song_summary['total_song_score'] = (song_summary['peak_score'] + song_summary['longevity_score'] +\n",
    "                                        song_summary['top10_bonus'] + song_summary['num1_bonus'])\n",
    "    print(\"  Summing song scores to get final artist scores...\")\n",
    "    artist_scores = song_summary.groupby('artist', observed=True)['total_song_score'].sum()\n",
    "    return artist_scores.sort_values(ascending=False)\n",
    "\n",
    "# Calculate scores using the Billboard 'artist' column\n",
    "artist_scores = calculate_artist_success(df.copy(), W_PEAK, W_LONGEVITY, B_TOP10, B_NUM1)\n",
    "\n",
    "\n",
    "# --- Filter by Artist Score ---\n",
    "# Logic unchanged, filters based on the calculated scores\n",
    "if artist_scores.empty or artist_scores.isna().all():\n",
    "    print(\"\\nWARNING: Artist scores could not be calculated. Skipping filtering by score.\")\n",
    "    df_filtered = df.copy()\n",
    "else:\n",
    "    # (Filtering logic based on ARTIST_SCORE_THRESHOLD_PERCENTILE is unchanged)\n",
    "    print(f\"\\nCalculated success scores for {len(artist_scores)} artists (Billboard names).\")\n",
    "    print(\"Top 10 Artists by Calculated Success Score:\")\n",
    "    print(artist_scores.head(10))\n",
    "    print(f\"\\nFiltering for 'Bigger Artists' (Top {(1-ARTIST_SCORE_THRESHOLD_PERCENTILE)*100:.0f}% by score)...\")\n",
    "    if ARTIST_SCORE_THRESHOLD_PERCENTILE > 0.0 and ARTIST_SCORE_THRESHOLD_PERCENTILE < 1.0 :\n",
    "        score_threshold = artist_scores.quantile(1 - ARTIST_SCORE_THRESHOLD_PERCENTILE)\n",
    "        bigger_artists_list = artist_scores[artist_scores >= score_threshold].index.tolist()\n",
    "        print(f\"  Score threshold: {score_threshold:.2f}\")\n",
    "        print(f\"  Identified {len(bigger_artists_list)} artists meeting the threshold.\")\n",
    "        if 'artist' in df.columns:\n",
    "            df_filtered = df[df['artist'].isin(bigger_artists_list)].copy()\n",
    "            print(f\"  DataFrame filtered to {len(df_filtered)} rows for bigger artists.\")\n",
    "        else:\n",
    "            print(\"  WARNING: 'artist' column missing, cannot filter by bigger artists score. Keeping all data.\")\n",
    "            df_filtered = df.copy()\n",
    "    elif ARTIST_SCORE_THRESHOLD_PERCENTILE >= 1.0:\n",
    "         print(f\"  Threshold percentile ({ARTIST_SCORE_THRESHOLD_PERCENTILE}) >= 100%, keeping no artists based on this filter.\")\n",
    "         df_filtered = df.iloc[0:0].copy()\n",
    "    else: # <= 0.0\n",
    "        print(\"  Threshold percentile <= 0, keeping all artists.\")\n",
    "        df_filtered = df.copy()\n",
    "\n",
    "# --- Add Artist Success Score as a Column ---\n",
    "# Logic unchanged, maps score based on Billboard 'artist' name\n",
    "if 'artist' in df_filtered.columns:\n",
    "    if not artist_scores.empty:\n",
    "        print(\"Adding Artist Success Score column to the DataFrame...\")\n",
    "        df_filtered['artist_success_score'] = df_filtered['artist'].map(artist_scores)\n",
    "        df_filtered['artist_success_score'].fillna(0, inplace=True)\n",
    "    else:\n",
    "        print(\"Artist scores are empty, adding 'artist_success_score' column with default 0.\")\n",
    "        df_filtered['artist_success_score'] = 0\n",
    "else:\n",
    "    print(\"WARNING: 'artist' column missing in df_filtered. Cannot add 'artist_success_score'.\")\n",
    "    df_filtered['artist_success_score'] = 0\n",
    "\n",
    "\n",
    "# --- Genre Filtering (Using Spotify Data) ---\n",
    "print(f\"\\nGenre Filtering Section (Target Keyword: '{TARGET_GENRE_KEYWORD}')\")\n",
    "if PERFORM_GENRE_FILTER:\n",
    "    print(f\"Attempting to filter based on Spotify 'artist_genres' or 'album_genres'...\")\n",
    "    # Check if either genre column exists\n",
    "    artist_genre_col = 'artist_genres' if 'artist_genres' in df_filtered.columns else None\n",
    "    album_genre_col = 'album_genres' if 'album_genres' in df_filtered.columns else None\n",
    "\n",
    "    if artist_genre_col or album_genre_col:\n",
    "        original_row_count = len(df_filtered)\n",
    "        # Create a boolean mask: True if keyword found in either artist or album genres\n",
    "        mask = pd.Series(False, index=df_filtered.index) # Start with all False\n",
    "        if artist_genre_col:\n",
    "            # Ensure string, handle NaN, search case-insensitively\n",
    "            mask |= df_filtered[artist_genre_col].astype(str).fillna('').str.contains(TARGET_GENRE_KEYWORD, case=False, na=False)\n",
    "        if album_genre_col:\n",
    "            mask |= df_filtered[album_genre_col].astype(str).fillna('').str.contains(TARGET_GENRE_KEYWORD, case=False, na=False)\n",
    "\n",
    "        df_filtered = df_filtered[mask]\n",
    "        print(f\"  Filtered from {original_row_count} to {len(df_filtered)} rows based on genre keyword '{TARGET_GENRE_KEYWORD}'.\")\n",
    "        if len(df_filtered) == 0:\n",
    "            print(f\"  WARNING: Genre filter resulted in zero rows. Check keyword or Spotify genre data availability.\")\n",
    "    else:\n",
    "        print(f\"  WARNING: Neither 'artist_genres' nor 'album_genres' column found. Skipping genre filter.\")\n",
    "else:\n",
    "    print(\"  Genre filtering is currently disabled (PERFORM_GENRE_FILTER = False).\")\n",
    "\n",
    "\n",
    "# --- Final Data Preparation & Output ---\n",
    "print(\"\\n--- Preparing Final Data and Saving ---\")\n",
    "\n",
    "# Define the desired order of columns for the final CSV output\n",
    "final_columns = [\n",
    "    # Billboard core\n",
    "    'chart_date', 'chart_name', 'rank', 'title', 'artist',\n",
    "    'artist_success_score',\n",
    "    'peak_pos', 'last_pos', 'weeks_on_chart', 'is_new',\n",
    "    # Spotify track specific\n",
    "    'spotify_id', 'spotify_track_name', 'spotify_primary_artist', 'spotify_all_artists',\n",
    "    'spotify_track_url', 'popularity', 'duration_ms', 'explicit',\n",
    "    # Spotify album specific\n",
    "    'album_id', 'album_name', 'album_release_date', 'album_total_tracks', 'album_url',\n",
    "    'artist_genres', 'album_genres', 'album_label', 'album_copyrights',\n",
    "    # Placeholders / Hard to get consistently\n",
    "    'writers', 'producers',\n",
    "]\n",
    "\n",
    "# Ensure all desired columns exist, adding any missing ones with None/NaN\n",
    "print(\"Ensuring all final columns exist...\")\n",
    "for col in final_columns:\n",
    "    if col not in df_filtered.columns:\n",
    "        print(f\"  Adding missing final column: '{col}'\")\n",
    "        df_filtered[col] = None # Add missing column with None/NaN\n",
    "\n",
    "# Reorder DataFrame columns using only columns that actually exist\n",
    "existing_final_columns = [col for col in final_columns if col in df_filtered.columns]\n",
    "df_final = df_filtered[existing_final_columns]\n",
    "\n",
    "# Display some info about the final dataset\n",
    "print(f\"\\nFinal processed dataset contains {len(df_final)} rows and {len(df_final.columns)} columns.\")\n",
    "# (Messages about filtering status remain similar)\n",
    "\n",
    "\n",
    "# Save the final processed DataFrame to a CSV file\n",
    "if df_final.empty:\n",
    "    print(\"\\nWARNING: Final DataFrame is empty. Skipping save to CSV.\")\n",
    "else:\n",
    "    try:\n",
    "        df_final.to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8')\n",
    "        print(f\"\\nSuccessfully saved final filtered data to: {OUTPUT_CSV_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: Failed to save data to CSV file. Error: {e}\")\n",
    "\n",
    "print(\"\\n--- Script Execution Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
